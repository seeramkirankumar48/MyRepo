hdfs is used to store the large files with streaming data access patterns on an commodity hardware.
hdfs can tolerate the node failure.
hdfs tolerates the node failure with the help of replication factor configured in the config files.
streaming data access pattern is such that it can read the entire data(in blocks) off from the disk using minimal seeks and maximum I/O of the disk.hdfs follows WORM (write once read many times) pattern hence there is much emphasis on reading many times for different jobs.
why go for dfs??
when size of the file is larger than the size of the disk it is neccessary to store the file in mulitple systems.
hdfs is not a good fit for::
1.low latency data access::
since it is used for batch processing it is not useful to get the high throughput(the amount of time taking to process) of the data.Hbase is used in this case.
2.lots of small files::
since the NN memory is limited and writing a file metadata to the NN memory will take around from 150 bytes to 200 bytes.
assuming there are 1 million files to be written to memory= (1 million files inodes+ 1 million blocks) *150 bytes ~= 300 mb
storing million is possible and billion is out of reach
the maximum amount of files that we can store in the hadoop cluster is determined by the NN memory.
3.multiple writers and arbitrary modifications::
hadoop doesn't support for the multiple writers and whenever we want to modify a file it only appends at the end of the file in append only fashion so we cannot modify a file in between.

-->the NN maintains the metadata information in 2 files namely,
FSImage (filesystem image)
editslog
When the NN containing information is lost the complete information in the cluster is lost and there is no way to construct the data from the datanodes.
hence it is called as SPOF(single point of failure).
so, it is required to maintain the NN data persistent to failures.
there are 2 ways to do this::
1.maintaining the metadata writes in 2 places such as local as well NFS(network file system)
2.maintaining the secondary name node::
the SNN will keepon merging the namespace image by not growing the edits log file by certain configurations such as limiting the transactions or for a particular amount of time. hence it is obvious that in the event of complete failure of the NN there is only a minimal amount of data loss(edits log info).In the event of NN failure the secondary NN may and can be configured by loading the entire information on NFS to inmemory and act it as a NN.

Block Caching::
the most frequently used blocks in the datanode are cached which in turn will be useful when running the mapreduce tasks on them.

Namenode HA::
-------------
since, NN is SPOF, if it fails then the entire mapreduce jobs running on the cluster could be failed. and hence it is mandatory to make the Namenode HA.
since making all of the metadata in SNN will take time it is necessary to run an passive namenode provided if,
1.The entire NN fs image is loaded into the memory
2.replayed its editslog
3.recieved enough block information from the datanodes to leave the safe mode.
since, the SNN functionality is subsumed by the passive or standby namenode.it is neccessary to make edits log information more highly available.hence NFS or QJM (which will be written to the majority of the journal nodes).so that standby node reads the data from the QJM incase of active failover.
the data blocks information is sent both to the active as well as passive namenodes.
clients must be configured to handle NN failover.
if the active NN fails then the standby NN can quickly come into the picture because it has all the available metadata and the block information.

Failover and Fencing::
----------------------






















doubts::
--------
1.what are the different configurations in the different config files?
2.what are inodes?




